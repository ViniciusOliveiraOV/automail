# .env.example - copy to .env and fill values before running the app
# Keep your real .env (with secrets) out of version control.

# App configuration
APP_CONFIG=development
FLASK_DEBUG=1
HOST=127.0.0.1
PORT=5000
SECRET_KEY=replace-with-a-random-secret
MAX_CONTENT_LENGTH=5242880

# Optional features
ENABLE_OCR=0      # set to 1 to enable OCR (requires Tesseract + pytesseract/Pillow)
LOAD_MODEL=0      # set to 1 to load a local ML model (joblib) at MODEL_PATH
MODEL_PATH=app/nlp/email_classifier_model.pkl

# Mail/IMAP (optional)
IMAP_HOST=imap.example.com
IMAP_USERNAME=user@example.com
IMAP_PASSWORD=change-me
IMAP_MAILBOX=INBOX

# Hugging Face Inference API (optional)
HF_API_TOKEN=
HF_API_URL=https://api-inference.huggingface.co/models
HF_MODEL=google/flan-t5-large
HF_MODEL_CANDIDATES=google/flan-t5-large,facebook/bart-large-mnli
HF_TIMEOUT=12.0
HF_ASYNC=0
LLM_WORKERS=2

# Grok / x.ai API (optional)
GROK_API_KEY=
GROK_API_URL=https://api.x.ai/v1/chat/completions

# Debug flags for AI calls (0/1)
AI_DBG=0
AI_DBG_RAW=0

# Usage notes:
# - Copy to .env and fill secrets before running:
#     cp .env.example .env
#   On PowerShell:
#     Copy-Item .env.example .env
# - Local Docker workflow (recommended for newcomers):
#     make build   # builds development images
#     make up      # runs docker-compose (dev) up --build
# - To run without Docker: create a venv and `pip install -r requirements.txt`, then run
#     python -m app.main
# - Do not commit your real .env to the repository.