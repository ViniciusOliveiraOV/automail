# .env.example - copy to .env and fill values before running the app
# Keep your real .env (with secrets) out of version control.

# App configuration
APP_CONFIG=development
FLASK_DEBUG=1
HOST=127.0.0.1
PORT=5000
SECRET_KEY=replace-with-a-random-secret
MAX_CONTENT_LENGTH=5242880

# Optional features
ENABLE_OCR=0      # set to 1 to enable OCR (requires Tesseract + pytesseract/Pillow)
LOAD_MODEL=0      # set to 1 to load a local ML model (joblib) at MODEL_PATH
MODEL_PATH=app/nlp/email_classifier_model.pkl

# Mail/IMAP (optional)
IMAP_HOST=imap.example.com
IMAP_USERNAME=user@example.com
IMAP_PASSWORD=change-me
IMAP_MAILBOX=INBOX

# Hugging Face Inference API (optional)
HF_API_TOKEN=
HF_API_URL=https://api-inference.huggingface.co/models
HF_MODEL=google/flan-t5-large
HF_MODEL_CANDIDATES=google/flan-t5-large,facebook/bart-large-mnli
HF_TIMEOUT=12.0
HF_ASYNC=0
LLM_WORKERS=2

# Grok / x.ai API (optional)
GROK_API_KEY=
GROK_API_URL=https://api.x.ai/v1/chat/completions

# Debug flags for AI calls (0/1)
AI_DBG=0
AI_DBG_RAW=0

# Observações de uso:
# - Copie para .env e preencha os segredos antes de executar:
#     cp .env.example .env
#   No PowerShell:
#     Copy-Item .env.example .env
# - Fluxo local com Docker (recomendado para iniciantes):
#     make build   # constrói as imagens de desenvolvimento
#     make up      # executa docker-compose (dev) up --build
# - Para rodar sem Docker: crie um venv e `pip install -r requirements.txt`, depois execute
#     python -m app.main
# - Não comite seu .env real no repositório.